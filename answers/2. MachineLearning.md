<div align='center'>
  <h1>🤖 Machine Learning 🤖</h1>
</div>


## Questions ❓

- [알고 있는 metric에 대해 설명해주세요. (ex. RMSE, MAE, recall, precision ...)](#no1)
- [정규화를 왜 해야할까요? 정규화의 방법은 무엇이 있나요?](#no2)
- [Local Minima와 Global Minima에 대해 설명해주세요.](#no3)
- [차원의 저주에 대해 설명해주세요.](#no4)
- [dimension reduction기법으로 보통 어떤 것들이 있나요?](#no5)
- [PCA는 차원 축소 기법이면서, 데이터 압축 기법이기도 하고, 노이즈 제거기법이기도 합니다. 왜 그런지 설명해주실 수 있나요?](#no6)
- [LSA, LDA, SVD 등의 약자들이 어떤 뜻이고 서로 어떤 관계를 가지는지 설명할 수 있나요?](#no7)
- [Markov Chain을 고등학생에게 설명하려면 어떤 방식이 제일 좋을까요?](#no8)
- [텍스트 더미에서 주제를 추출해야 합니다. 어떤 방식으로 접근해 나가시겠나요?](#no9)
- [SVM은 왜 반대로 차원을 확장시키는 방식으로 동작할까요? SVM은 왜 좋을까요?](#no10)
- [ 다른 좋은 머신 러닝 대비, 오래된 기법인 나이브 베이즈(naive bayes)의 장점을 옹호해보세요.](#no11)
- [회귀 / 분류시 알맞은 metric은 무엇일까요?](#no12)
- [다른 좋은 머신 러닝 대비, 오래된 기법인 나이브 베이즈(naive bayes)의 장점을 옹호해보세요.](#no11)
- [회귀 / 분류시 알맞은 metric은 무엇일까요?](#no12)
- [Association Rule의 Support, Confidence, Lift에 대해 설명해주세요.](#no13)
- [최적화 기법중 Newton’s Method와 Gradient Descent 방법에 대해 알고 있나요?](#no14)
- [머신러닝(machine)적 접근방법과 통계(statistics)적 접근방법의 둘간에 차이에 대한 견해가 있나요?](#no15)
- [인공신경망(deep learning이전의 전통적인)이 가지는 일반적인 문제점은 무엇일까요?](#no16)
- [지금 나오고 있는 deep learning 계열의 혁신의 근간은 무엇이라고 생각하시나요?](#no17)
- [ROC 커브에 대해 설명해주실 수 있으신가요?](#no18)
- [여러분이 서버를 100대 가지고 있습니다. 이때 인공신경망보다 Random Forest를 써야하는 이유는 뭘까요?](#no19)
- [K-means의 대표적 의미론적 단점은 무엇인가요? (계산량 많다는것 말고)](#no20)
- [L1, L2 정규화에 대해 설명해주세요.](#no21)
- [Cross Validation은 무엇이고 어떻게 해야하나요?](#no22)
- [XGBoost을 아시나요? 왜 이 모델이 캐글에서 유명할까요?](#no23)
- [앙상블 방법엔 어떤 것들이 있나요?](#no24)
- [feature vector란 무엇일까요?](#no25)
- [좋은 모델의 정의는 무엇일까요?](#no25)
- [50개의 작은 의사결정 나무는 큰 의사결정 나무보다 괜찮을까요? 왜 그렇게 생각하나요?](#no26)
- [스팸 필터에 로지스틱 리그레션을 많이 사용하는 이유는 무엇일까요?](#no28)
- [OLS(ordinary least squre) regression의 공식은 무엇인가요?](#no29)

---

### No.1

**알고 있는 metric에 대해 설명해주세요. (ex. RMSE, MAE, recall, precision ...)**

1. RMSE-like metrics
   * [MAE](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/MeanAbsoluteError): Mean Absolute Error, 오차 평균; 오차의 단위가 실제 타겟값의 단위와 똑같다는 특징이 있으며 이상치에 덜 민감하다.
   * [RMSE](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/RootMeanSquaredError): Root Mean Squared Error, 오차 제곱 평균의 제곱근; MAE와 마찬가지로 오차의 단위가 실제 타겟값의 단위와 똑같아서 직관적이다. MAE와는 달리 큰 오차값이 더 반영되어 이상치에 더 민감하다는 특징을 갖고 있다.
   * [MSE](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/MeanSquaredError): Mean Squared Error, 오차 제곱 평균; RMSE와 같이 큰 오차값을 더 반영하는 평가지표지만, 실제 타겟값과 단위가 달라서 직관적이지는 않다. MAE, RMSE와 같이 회귀 문제에서 자주 사용되는 평가지표다.
   * [MAPE](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/MeanAbsolutePercentageError): Mean Absolute Percentage Error, 오차 평균 백분율; 오차를 실제값 y로 나누어 MAE를 백분율 단위로 변경한 것으로, MAE와 많은 공통점을 지니지만 y가 0일 때 사용할 수 없다는 단점이 추가로 존재한다. 백분율 단위의 직관성이 장점이지만, 예측값과 실제값의 대소관계가 지표의 크기에 반영이 되는 특징이 있어 주의가 필요하다. (예/ n=1일 때, 예측값:10/실제값:20 → MAPE = 50% ; 예측값:20/실제값:10 → MAPE = 100%)
2. confusion matrix related metrics
   * [Precision](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Precision)(정밀도): True Positives / Predicted Positives = True Positives / (True Positives + False Positives): 1종 오류와 관련이 있는 분류 평가 지표. (예/ 스팸 방지 - 스팸메일이 받은메일함으로 분류되는 것보다 정상 메일이 스팸메일함으로 분류되는 것을 더 지양)
   * [Recall](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Recall) = Sensitivity(민감도): True Positives / Real Positives = True Positives / (True Positives + False Negatives); 2종 오류와 관련이 있는 분류 평가 지표. (예/ 의료 데이터 분석 - 양성으로 잘못 분류하는 것보다 음성으로 잘못 분류하여 환자를 놓치는 경우를 더 지양)
   * Specificity(특이도): True Negatives / Real Negatives = True Negatives / (True Negatives + False Positives); False Alarm(False Positive)를 방지하고자 할때 사용. (예/ 마약복용자를 구속하지 않는 것보다 일반인을 잘못 구속하는 경우를 더 지양)
   * [Precision at Recall](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/PrecisionAtRecall) / [Recall at Precision](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/RecallAtPrecision) : 특정 Recall 값에서의 Precision 측정 또는 특정 Precision 값에서의 Recall 측정
3. [AUC](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/AUC)
   * ROC-AUC: ROC(Receiver Operating Characteristic) 곡선 아래의 면적(0~1); True Positive Rate(=Recall=TP/(TP+FN))과 False Positive Rate(=FP/(FP+TN))의 tradeoff 관계를 시각화하는 지표; 랜덤한 이진 분류의 경우 ROC-AUC 값은 0.5.
   * PR-AUC: Precision-Recall 곡선 아래의 면적(0~1); 음악 장르와 같이 대부분이 0으로 이루어진 (imbalanced 한) 레이블 벡터 y를 타겟으로 할 때는 PR-AUC가 ROC-AUC보다 더 정확한 직관을 주는 것으로 알려져 있음. (True Negative의 영향 때문)
4. crossentropy
   * [binary crossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/BinaryCrossentropy): 이진분류 문제에 사용할 수 있는 crossentropy 기반 분류 지표.
   * [categorical crossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/CategoricalCrossentropy): multi-label분류 문제에 사용할 수 있는 crossentropy 기반 분류 지표.

참고문헌
- [TensorFlow tf.keras.metrics API docs](https://www.tensorflow.org/api_docs/python/tf/keras/metrics)
- [Regression Metrics for Machine Learning](https://machinelearningmastery.com/regression-metrics-for-machine-learning/)
- [Tutorial: Understanding Regression Error Metrics in Python](https://www.dataquest.io/blog/understanding-regression-error-metrics/)
- [Accuracy, Recall, Precision, F-Score & Specificity, which to optimize on?](https://towardsdatascience.com/accuracy-recall-precision-f-score-specificity-which-to-optimize-on-867d3f11124)
- [F1 Score vs ROC AUC vs Accuracy vs PR AUC: Which Evaluation Metric Should You Choose?](https://neptune.ai/blog/f1-score-accuracy-roc-auc-pr-auc)
- [이진 분류기 성능 평가방법 AUC(area under the ROC curve)의 이해.txt](https://bskyvision.com/1165)
- [Cross-entropy for classification](https://towardsdatascience.com/cross-entropy-for-classification-d98e7f974451)

---
### No.2
**정규화를 왜 해야할까요? 정규화의 방법은 무엇이 있나요?**

다양한 정규화 방법들을 통해서 기계학습 알고리즘의 성능을 증가시킬 수 있으며, 알고리즘들마다 정규화의 효과가 다를 수 있어 실험을 해보는 것이 좋다. 거리기반의 SVM, KNN 알고리즘과 MLP 알고리즘은 특히 정규화의 효능이 좋은 편이다.

1. Normalization (min-max normalization): 값들을 0에서 1사이 범위로 rescaling하는 것을 뜻한다.
2. Standardization (Z-score standardization): 평균 0 표준편차 1의 분포를 띄도록 rescaling하는 것을 뜻한다.

특히 딥러닝에서 정규화는 오랜 기간동안 연구 대상으로 주목 받고 있었으며, 정규화를 수행하는 방향 또한 중요하다고 알려져 있다.

![normalization](https://miro.medium.com/max/1400/1*r0HM4TvZvvceXcJIpDJmDQ.png)

1. Batch Normalization: mini-batch 내 같은 feature들끼리 정규화를 수행하는 방법이다. 보통 CNN 모델에서 많이 사용된다. batch 사이즈가 너무 작을 때는 오히려 악역향을 끼칠 수 있다고도 한다.
2. Layer Normalization: 각 데이터 포인트 전체에 대하여 정규화를 수행하는 방법이다. 보통 RNN 또는 Transformer 모델에서 많이 사용된다.

  참고문헌
  - [Normalization vs Standardization — Quantitative analysis](https://towardsdatascience.com/normalization-vs-standardization-quantitative-analysis-a91e8a79cebf)
  - [Normalization Techniques in Deep Neural Networks](https://medium.com/techspace-usict/normalization-techniques-in-deep-neural-networks-9121bf100d8)

---

### No.3
**Local Minima와 Global Minima에 대해 설명해주세요.**

(손실) 함수 전체의 가장 최소값이 global minima이며, gradient decent 등의 최적화 알고리즘으로 찾을 수 있는 global minima 외 최소값들을 local minima라고 한다. 기계학습 최적화 알고리즘들은 local minima에 빠져서 global minima를 찾지 못할 가능성이 항상 존재한다.

![animation](https://vitalflux.com/wp-content/uploads/2020/10/local_minima_vs_global_minima.gif)

global minima를 올바르게 찾기 위해서는 feature engineering을 조심히 해야하며, 다양한 learning rate schedule과 여러 step수를 실험해볼 필요가 있다.

참고문헌

- [Local & Global Minima Explained with Examples](https://vitalflux.com/local-global-maxima-minima-explained-examples/)
---

### No.4
**차원의 저주에 대해 설명해주세요.**

`차원의 저주`란 데이터 학습을 위해 차원이 증가(=변수의 수 증가)하면서 학습 데이터의 수가 차원의 수보다 적어져 성능이 저하되는 현상을 말한다. 즉, 간단히 말하면 차원이 증가함에 따라 모델의 성능이 안 좋아지는 현상을 의미한다.

무조건 변수의 수가 증가한다고 해서 차원의 저주 문제가 있는 것이 아니라, `관측치 수보다 변수의 수가 많아지면` 발생한다. 예를 들어, 관측치의 수는 200개인데, 변수는 7000개인 경우 차원의 저주가 발생하게 된다.

<img src="https://user-images.githubusercontent.com/57162812/150798251-f38d8347-b146-44ee-9056-15194951a7d3.png" width=600>

차원이 늘어날 때마다 점들 사이의 간격이 벌어지게 된다. 즉, 빈 공간이 생기게 되는데 이는 컴퓨터 상에서 0으로 채워졌다는 뜻으로 정보가 없는 셈이다. 정보가 적기 때문에 모델을 돌릴 때 성능이 저하되게 된다. 여기서 빈 공간이 생기는 것을 차원의 저주라고 한다.

차원의 저주를 해결할 수 있는 방법에는 차원을 축소시키거나 데이터를 많이 획득하는 것이 있다.

참고문헌
- [[빅데이터] 차원의 저주(The curse of dimensionality)](https://datapedia.tistory.com/15)

---

### No.5
**dimension reduction기법으로 보통 어떤 것들이 있나요?**

`차원 축소` : 매우 많은 피처로 구성된 다차원 데이터 세트의 타원을 축소해 새로운 차원의 데이터 세트를 생성하는 것

차원 축소는 **피처 선택**과 **피처 추출**로 나눌 수 있다.

`피처 선택`은 특정 피처에 종속성이 강한 불필요한 피처는 아예 제거하는 것이며, `피처 추출`은 기존 피처를 저차원의 중요 피처로 압축해서 추출하는 것이다.

피쳐 선택의 장점은 선택한 피처의 해석이 용이하다는 점이고, 단점은 피처간의 상관관계를 고려하기 어렵다는 점이다.

피처 추출의 장점은 피처 간 상관관계를 고려하기 용이하며 피처의 개수를 많이 줄일 수 있다는 점이고, 단점은 추출된 변수의 해석이 어렵다는 점이다. 대표적인 피처 추출 알고리즘으로는 PCA, SVD, NMF, LDA 등이 있다.

참고 문헌
- [차원 축소 (Dimension Reduction) - PCA, LDA](https://casa-de-feel.tistory.com/19)

---
### No.6
**PCA는 차원 축소 기법이면서, 데이터 압축 기법이기도 하고, 노이즈 제거기법이기도 합니다. 왜 그런지 설명해주실 수 있나요?**

주성분 분석은 차원이 큰 벡터에서 선형 독립하는 고유 벡터만을 남겨두고 차원을 축소하게 된다. 이때 상관성이 높은 독립 변수들을 N개의 선형 조합으로 만들며 개수를 요약, 압축해내는 기법이다. 그리고 이 압축된 각각의 돌깁 변수들은 선형 독립, 즉 직교하며 낮은 상관성을 보이게 된다. 또한 정보 설명력이 높은 주성분들만 선택하면서 정보 설명력이 낮은, 노이즈로 구성된 칼럼들을 배제하기 때문에 노이즈 제거 기법이라고도 불린다.

참고 문헌
- [[기술면접] 차원축소, PCA, SVD, LSA, LDA, MF 간단정리 (day1 / 201009) - Hui_dea](https://huidea.tistory.com/126)

---

### No.7
**LSA, LDA, SVD 등의 약자들이 어떤 뜻이고 서로 어떤 관계를 가지는지 설명할 수 있나요?**

LSA와 LDA는 자연어 처리 분야에서 토픽 모델링과 관련이 있고, 이 두 개의 모델링 중 LSA에 SVD가 사용된다.(토픽 모델링이란 텍스트 본문의 숨겨진 의미 구조를 발견하기 위해 사용되는 텍스트 마이닝 기법이다.) 따라서 LSA와 LDA를 설명함에 앞서 SVD를 먼저 이해할 필요가 있다. 

**SVD(Singular Value Decomposition)**: 특이값 분해(SVD)는 행렬을 특정한 구조로 분해하는 방식이다. 3개의 구조로 분해되는데, 이 중 기존 데이터의 정보량을 의미하는 행렬의 원소들을 특이값(singular value)이라고 불러 SVD라고 부른다.  

<img src="https://latex.codecogs.com/svg.image?m&space;\times&space;n" title="m \times n" /> 크기의 행렬 <img src="https://latex.codecogs.com/svg.image?A" title="A" />가 있다고 하자. 행렬 <img src="https://latex.codecogs.com/svg.image?A" title="A" />는 SVD를 통해 아래와 같이 세 개의 행렬로 나누어진다.

<img src="https://latex.codecogs.com/svg.image?A_{[m&space;\times&space;n]}=U_{[m&space;\times&space;r]}&space;\times&space;\sum_{[r&space;\times&space;r]}&space;\times&space;(V_{[n&space;\times&space;r]})^T" title="A_{[m \times n]}=U_{[m \times r]} \times \sum_{[r \times r]} \times (V_{[n \times r]})^T" />  

여기서 각 행렬은 다음과 같은 성질을 가진다.

* <img src="https://latex.codecogs.com/svg.image?A" title="A" /> : <img src="https://latex.codecogs.com/svg.image?m&space;\times&space;n" title="m \times n" /> 크기의 입력 행렬(Input data)  
   * <img src="https://latex.codecogs.com/svg.image?m" title="m" />개의 단어, <img src="https://latex.codecogs.com/svg.image?n" title="n" />개의 문서. 행렬의 값들은 각 문서에 해당 단어가 등장하는 빈도수  

* <img src="https://latex.codecogs.com/svg.image?U" title="U" /> : <img src="https://latex.codecogs.com/svg.image?m&space;\times&space;r" title="m \times r" /> 크기의 직교 행렬<img src="https://latex.codecogs.com/svg.image?(U&space;\times&space;U^T&space;=&space;I)" title="(U \times U^T = I)" />.
   * <img src="https://latex.codecogs.com/svg.image?m" title="m" />개의 단어, <img src="https://latex.codecogs.com/svg.image?r" title="r" /> 개의 컨셉  

* <img src="https://latex.codecogs.com/svg.image?&space;\sum&space;" title=" \sum " /> : <img src="https://latex.codecogs.com/svg.image?r&space;\times&space;r" title="r \times r" /> 크기의 대각 행렬. 좌상부터 descending order로 값들이 저장된다(중요도 순).
   * <img src="https://latex.codecogs.com/svg.image?r" title="r" /> 컨셉의 중요도

* <img src="https://latex.codecogs.com/svg.image?V" title="V" /> : <img src="https://latex.codecogs.com/svg.image?n\times&space;r" title="n\times r" /> 크기의 직교 행렬<img src="https://latex.codecogs.com/svg.image?(V&space;\times&space;V^T&space;=&space;I)" title="(V \times V^T = I)" />.
   * <img src="https://latex.codecogs.com/svg.image?n" title="n" />개의 문서, <img src="https://latex.codecogs.com/svg.image?r" title="r" /> 개의 컨셉 

SVD를 통해 행렬의 정보를 압축시킬 수 있다. 이는 아래 이미지처럼 <img src="https://latex.codecogs.com/svg.image?r" title="r" /> 개의 컨셉 중 상위 <img src="https://latex.codecogs.com/svg.image?k" title="k" />개의 중요한 컨셉을 추출함으로써 이루어진다. <img src="https://latex.codecogs.com/svg.image?\sum_{[r&space;\times&space;r]}" title="\sum_{[r \times r]}" />의 행렬을 <img src="https://latex.codecogs.com/svg.image?\sum_{[k&space;\times&space;k]}" title="\sum_{[k \times k]}" /> 행렬로 줄여도 기존의 <img src="https://latex.codecogs.com/svg.image?m&space;\times&space;n" title="m \times n" /> 크기를 유지할 수 있기 때문이다. 중요도가 낮은 컨셉(노이즈)을 제거함으로써 데이터를 압축할 수 있는 것이다. 이처럼 덜 중요하다고 생각하는 정보를 제거하는 방식을 Truncated SVD라고 부른다.

<img width="500" alt="svd-2" src="https://user-images.githubusercontent.com/63924704/150988716-98bc4ed2-9234-412c-9cca-881acd30f924.png">

SVD는 이미지 압축에서도 사용된다. 이미지를 정보량(<img src="https://latex.codecogs.com/svg.image?\sum" title="\sum" />의 대각 원소. singular value 혹은 scaling factor라고 부름)에 따라 중요한 정보를 위주로 남기고, 나머지를 버리기 때문에 이미지를 압축하면 (d)와 같이 화질이 깨져 보이게 된다.

<img width="300" alt="svd-4" src="https://user-images.githubusercontent.com/63924704/150988771-0017af6d-6a6c-4761-9623-06ae8464569d.png">


**LSA(Latent Semantic Analysis, 잠재 의미 분석)**: 빈도주의에 기반한 Bag-of-Words(BOW)를 사용하여 문서-단어 행렬(Document-Term Matrix, DTM)로 구성된 데이터의 차원 축소기법으로써, 데이터의 숨어있는 의미를 효과적으로 추출하는 방법이다. 여기서 문서 단어 행렬이란 다수의 문서에서 등장하는 각 단어들의 빈도를 행렬로 표현한 것을 말한다. 쉽게 말해 각 문서에 등장하는 단어의 빈도수를 행렬로 표현한 것이다. LSA는 앞서 소개한 Truncated SVD의 방법을 그대로 이용한다. 

1. SVD를 통해 <img src="https://latex.codecogs.com/svg.image?m&space;\times&space;n" title="m \times n" /> 크기의 단어 정보들을 담은 행렬을 <img src="https://latex.codecogs.com/svg.image?U,&space;\sum,&space;V^T" title="U, \sum, V^T" />로 분해
2. 중요한 정보만 남기기
3. 축소된 차원의 행렬을 사용하여 정보가 압축된 새로운 문서로 데이터에 숨어있는 의미를 효과적으로 추출(의미 정보 함축)

<img width="500" height="300" alt="svd_1" src="https://user-images.githubusercontent.com/63924704/151112132-56466ba7-990f-485e-ba48-ab4d03c1f913.png">


**LDA(Latent Dirichlet Allocation, 잠재 디리클레 할당)**: 단어가 특정 토픽에 존재할 확률과 문서에 특정 토픽이 존재할 확률을 결합확률로 추정하여 토픽을 추출하는 토픽 모델링 알고리즘 중 하나이다.

정리하면, LSA와 LDA는 모두 문서 내 단어의 빈도수를 활용하여 분석하는데, LSA는 행렬 분해 기반의 정보 압축을 통해, LDA는 확률 기반의 모델링을 통해 이루어진다. 두 방법 모두 단어의 순서는 고려하지 않는다.

**[추가]**
* **LDA(Linear Discriminant Analysis)** : 차원축소기법 중 하나로 분류하기 쉽도록 클래스 간 분산을 최대화하고 클래스 내부의 분산은 최소화하는 방식을 말한다.

**[유용한 자료]**
- [특이값 분해(SVD) - 공돌이의 수학정리노트](https://angeloyeo.github.io/2019/08/01/SVD.html)
- [StatQuest: Linear Discriminant Analysis (LDA) clearly explained.](https://www.youtube.com/watch?v=azXCzI57Yfc&t=779s)

참고 문헌
- [위키백과 - 특이값 분해](https://ko.wikipedia.org/wiki/%ED%8A%B9%EC%9E%87%EA%B0%92_%EB%B6%84%ED%95%B4)
- [데이터과학 유망주의 매일 글쓰기](https://conanmoon.medium.com/%EB%8D%B0%EC%9D%B4%ED%84%B0%EA%B3%BC%ED%95%99-%EC%9C%A0%EB%A7%9D%EC%A3%BC%EC%9D%98-%EB%A7%A4%EC%9D%BC-%EA%B8%80%EC%93%B0%EA%B8%B0-59-f12da22613fd)
- [[토픽 모델링] LSA와 LDA의 관계 (+ LDA라는 이름의 유래)](https://bab2min.tistory.com/585)
- [문서 단어 행렬(Document-Term Matrix, DTM)](https://settlelib.tistory.com/61)

---

### No.8
**Markov Chain을 고등학생에게 설명하려면 어떤 방식이 제일 좋을까요?**

**마르코프 체인**이란 **마르코프 성질**을 지닌 **이산 확률 과정**을 의미한다. 

* 먼저 **확률 과정**은 시간에 따라 어떤 사건이 발생할 확률이 변화하는 과정을 의미한다.  
* **이산** 시간은 시간이 연속적으로 변하지 않고 이산적으로 변함을 의미한다.  
* **마코프 특성**은 과거 상태들(<img src="https://latex.codecogs.com/svg.image?s_1,&space;s_2,&space;...&space;,&space;s_{t-1}" title="s_1, s_2, ... , s_{t-1}" />)과 현재 상태(<img src="https://latex.codecogs.com/svg.image?s_t" title="s_t" />)가 주어졌을 때, 미래 상태(<img src="https://latex.codecogs.com/svg.image?s_{t&plus;1}" title="s_{t+1}" />)는 과거 상태와는 독립적으로 현재 상태에 의해서만 결정된다는 것을 의미한다.  

즉, 과거와 현재 상태 모두를 고려했을 때 미래 상태가 나타날 확률과 현재 상태만을 고려했을 때 미래 상태가 발생할 확률이 동일하다는 것이다. 이를 식으로 나타내면 다음과 같다.

<img src="https://latex.codecogs.com/svg.image?P(s_{t&plus;1}|s_t)&space;=&space;P(s_{t&plus;1}|s_t,&space;s_{t-1},&space;...&space;s_t)" title="P(s_{t+1}|s_t) = P(s_{t+1}|s_t, s_{t-1}, ... s_t)" />

마코프 체인은 이처럼 과거 상태를 기억하지 않기 때문에 메모리리스(memoryless) 프로세스로 불린다.

참고 문헌
- [MLWiki - Markov Chain](https://sites.google.com/site/machlearnwiki/RBM/markov-chain)
- [[강화학습] 마코프 프로세스(=마코프 체인) 제대로 이해하기](https://bskyvision.com/573)

---

### No.9
**텍스트 더미에서 주제를 추출해야 합니다. 어떤 방식으로 접근해 나가시겠나요?**

LDA(Latent Dirichlet Allocation) 알고리즘으로 접근할 수 있다. LDA는 단어 이면에 존재하는 정보를 추론하여 해당 단어가 어떤 주제에서 뽑힌 것인지 알아내는 과정이다. 

LDA는 문서 내의 토픽 분포(확률)와 각 토픽 내의 단어 분포(확률)을 추정한다(추정 시 사용하는 분포가 Dirichlet 분포이기 때문에 LDA라고 불림).  이때 토픽의 수는 하이퍼 파라미터로, 사용자가 직접 지정해줘야한다. 

LDA의 순서는 아래와 같다.
1. 단순 Count 기반 Document Term Matrix 행렬을 생성한다.(문서별 단어의 빈도수 행렬)
2. 사용자가 토픽의 개수를 사전에 설정한다.(하이퍼파라미터)
3. 각 단어들을 임의의 토픽으로 최초 할당하여 문서별 토픽 분포와 토픽별 단어 분포를 결정한다.
4. 특정 단어를 하나 추출하고 추출한 해당 단어를 제외하고 문서의 토픽 분포와 토픽별  단어 분포를 다시 계산한다.(이 과정을 깁스 샘플링이라고 한다.) 그리고 추출된 단어는 새롭게 토픽 할당 분포를 계산한다.
5. 모든 단어에 대해 4단계를 반복한다.
6. 모든 단어들의 토픽 할당 분포가 변경되지 않고 수렴할 때까지 수행한다.

> LDA 예시 - 사용자가 사전에 토픽 개수를 2개로 설정

문서1 : 저는 사과랑 바나나를 먹어요

문서2 : 우리는 귀여운 강아지가 좋아요

문서3 : 저의 깜찍하고 귀여운 강아지가 바나나를 먹어요

**<각 문서의 토픽 분포>**

문서1 : 토픽 A 100%

문서2 : 토픽 B 100%

문서3 : 토픽 B 60%, 토픽 A 40%

**<각 토픽의 단어 분포>**

토픽A : **사과 20%, 바나나 40%, 먹어요 40%**, 귀여운 0%, 강아지 0%, 깜찍하고 0%, 좋아요 0%

토픽B : 사과 0%, 바나나 0%, 먹어요 0%, **귀여운 33%, 강아지 33%, 깜찍하고 16%, 좋아요 16%**

LDA는 토픽의 제목을 정해주지 않지만, 이 시점에서 알고리즘의 사용자는 위 결과로부터 두 토픽이 각각 과일에 대한 토픽과 강아지에 대한 토픽이라고 판단해볼 수 있다.

**[유용한 자료]**
- [[잠재 디리클레 할당 파헤치기] 3. 깁스 샘플링으로 파라미터 추정](https://bab2min.tistory.com/569)

참고 문헌
- [[NLP] LDA를 활용한 Topic Modeling 구현하기](https://techblog-history-younghunjo1.tistory.com/112)
- [LDA 토픽모델링](https://www.youtube.com/watch?v=noWKlkdcY6A)
- [위키백과 - 디리클레 분포](https://ko.wikipedia.org/wiki/%EB%94%94%EB%A6%AC%ED%81%B4%EB%A0%88_%EB%B6%84%ED%8F%AC)
- [Topic Modeling, LDA](https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/06/01/LDA/)

------

### No.10

**SVM은 왜 반대로 차원을 확장시키는 방식으로 동작할까요? SVM은 왜 좋을까요?**

- **SVM**

  `SVM`은 지도학습 모델로 분류와 회귀분석에 사용되며, 선형모델이지만 차원 확장을 통해 비선형 문제를 선형문제로 해결할 수 있다. 

  - SVC(classification)

  - SVR (regression)

- **차원의 확장**

  ![image](https://user-images.githubusercontent.com/71866756/151286865-eeb3bc09-af43-4632-bd1b-aec1b3f8b889.png)


  선형으로 해결할 수 없는 분류 문제의 경우, 차원 확장을 통해 선형으로 해결할 수 있게 된다.  

- **kernel trick**

  원래 차원 확장에 이용되는 함수가 매핑 함수인데, 매핑 함수의 경우 고차원으로 매핑 후, 다시 내적을 해야하기 때문에 연산량이 매우 많다.

  이 함수를 직접 사용하는 대신 벡터 내적 연산을 대체하는 비선형 커널 함수를 정의해서 사용한다. (보통 RBF를 많이 사용한다.)

  <img src="https://github.com/boostcamp-ai-tech-4/ai-tech-interview/blob/main/images/adc/machine-learning/kernel.PNG?raw=true" alt="kernel.PNG" style="zoom: 80%;" />

  

- **용어설명**

  SVM은 margin을 최대한 크게 만드는 것이 목적이다. margin이 최대가 아닌 치우친 경우, 데이터를 분류하는데 

  <img src="https://t1.daumcdn.net/cfile/tistory/997C183B5E3A554502" alt="Support Vector Machine (SVM)" style="zoom:80%;" />

  - support vector : 데이터들 중 Hyper plane (결정 경계와 같은 의미)에 가장 가까운 데이터들을 의미한다. 
  - margin : hyper plane와 support vector 사이의 거리를 의미한다. 

- **SVM 장점**

  - 비선형 분리 데이터를 커널트릭을 사용하여 선형 분류 모델링 가능
  - Multicollinearity (다중공선성, 독립변수들 간에 상관관계가 높으면 안된다는 조건을 위배하는 것) 문제를 회피한다.
  - 신경망 기법에 비해서 과적합 정도가 덜하다
  - n개의 속성을 가진 데이터는 최소 n+1개의 서포트 벡터가 존재한다. ( 그래서 서포트 벡터만 잘 골라내면 나머지 데이터 포인트들은 무시할 수 있어 빠르다. )
  - local minimma에 빠지지 않는다.

- **SVM 단점**

  - 확률 추정치를 직접적으로 반환하지 않음
  - 결과에 대한 설명력이 떨어진다. 
  - kernel과 모델 파라미터를 조절하기 위한 테스트를 여러번 해봐야 최적화된 모형을 만들 수 있다. 

**[참고문헌]**

- [자세한 수식](https://ekdud7667.tistory.com/entry/SVMSupport-Vector-Machine)
- [SVM kernel](https://ratsgo.github.io/machine%20learning/2017/05/30/SVM3/)
- [대학원생의 입장에서 이해하는 SVM](https://jaejunyoo.blogspot.com/2018/01/support-vector-machine-1.html)

------

### No.11

**다른 좋은 머신 러닝 대비, 오래된 기법인 나이브 베이즈(naive bayes)의 장점을 옹호해보세요.**

`나이브 베이즈 분류기`는 베이즈 정리에 기반한 통계적 분류 기법으로 훈련 데이터를 활용해 특징 값이 제공하는 증거를 기반으로 결과가 관측될 확률을 계산한다. 

- **등장 배경**

  feature가 많을수록 학습에 필요한 파라미터가 매우 많아지며, 이를 계산하기 위해서는 복잡한 계산이 필요하게 된다. 따라서, 이러한 복잡성을 줄이기 위해서 나이브 베이즈 분류기가 등장했다. 

- **조건부 독립을 가정하는 이유**

  마찬가지로 계산의 복잡성을 줄이기 위하여 조건부 독립을 가정한다. 

  ![image](https://user-images.githubusercontent.com/71866756/151286990-0e7ecb9f-ed2e-4960-89b0-a2a82474f433.png)

  위 그림에서 정답 label (EnjoySpt)를 추정하기 위해서는 모든 feature들(sky, Temp, Humid, ...)을 고려해야 한다. 만약 조건부 독립이 아니라면    
  ![image](https://user-images.githubusercontent.com/71866756/151287020-3323f4fd-d73a-4aec-bd2d-a9ad5cdbddca.png)  
  위 수식을 계산하기 위해서는 복잡한 식이 필요하다. 

  하지만, 조건부 독립을 가정한다면  
  ![image](https://user-images.githubusercontent.com/71866756/151287049-b4897ef2-7d80-46e0-ad3e-cabae0f46bf1.png)  
  로 식을 간소화할 수 있다. 

| 장점                                                         | 단점                                                         |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| 매우 간단하며, 빠르고 효율적이다                             | 모든 특징이 동등하게 중요하고 조건부 독립이라고 가정하기 때문에 현실을 온전히 반영하지 못한다. |
| 잡음과 누락 데이터를 잘 처리한다                             | feature가 많은 데이터셋에는 이상적이지 않다                  |
| 훈련에는 상대적으로 적은 데이터가 필요하지만, 대용량의 데이터에도 잘 작동한다 | 관측 값을 통해 확률을 결정, 그에 따라 class를 분류하기 때문에 확률의 한계로 인한 오류가 발생할 수 있다. |
| 예측을 위한 추정 확률을 쉽게 얻을 수 있다                    |                                                              |

- **나이브 베이즈가 쓰이는 예시**
  - 스팸 이메일 필터링
  - 컴퓨터 네트워크에서의 침입/비정상행위 탐지
  - 일련의 관찰된 증상에 대한 의학적 질병 진단

**[참고문헌]**

- [인공지능 및 기계학습 개론](https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=arcia21&logNo=221049260461)

------

### No.12

**회귀 / 분류시 알맞은 metric은 무엇일까요?**

- **회귀문제**

  회귀문제에서는 실제 값과 예측 값의 차이에 기반을 둔 metric을 사용한다. 

  - MSE (Mean Squared Error)

    제곱 연산으로 인해 outlier에 대해서 견고하다.   
    ![image](https://user-images.githubusercontent.com/71866756/151287071-0cd9b9bc-3a7d-47e8-8a8b-80f8f4be0bf1.png)  

  - RMSE (Root Mean Squared Error)  
    ![image](https://user-images.githubusercontent.com/71866756/151287098-4d7b4b87-bcc5-4680-8464-e3f9c2f9ad1b.png)  

  - RMSLE (Root Mean Squared Log Error)

    outlier에 대해 견고하며, 상대적인 error를 측정한다.   
    ![image](https://user-images.githubusercontent.com/71866756/151287123-baf8e0ed-4c34-4da7-afc0-69577d63fb7a.png)  

  - MAE (Mean Absolute Error)  
    ![image](https://user-images.githubusercontent.com/71866756/151287149-e8ec8018-a6f5-40e1-a19a-1da3de2b375a.png)  

  - R2 (R-Squared)

    1에 가까울수록 설명령이 높다는 것을 의미한다.  
    ![image](https://user-images.githubusercontent.com/71866756/151287174-c4ccd397-73af-4aef-b5a3-a886816a2c45.png)  

- **분류문제**

  두 분포간의 차이를 줄이는 것이 중요하기 때문에, 보통 KL발산을 많이 사용한다. 

  KL은 엔트로피항과 크로스엔트로피 항으로 나뉘는데, 정답 label에 대한 값은 1이므로 엔트로피의 항이 결과적으로 0이 된다. 따라서 크로스 엔트로피를 줄이는 것과 KL발산을 줄이는 것은 같은 의미가 된다. 

  - CE (Cross Entropy)

    log를 취해줌으로써 정답이 1일 경우, 예측값이 1에 가까울수록 오차는 0에 수렴한다.

    반면, 1에서 멀어질수록 오차는 기하급수적으로 증가한다.   
    ![image](https://user-images.githubusercontent.com/71866756/151287219-1b101980-25c2-4b88-9079-2ed5797670db.png)  

  - CCE (Categorical Cross Entropy)

    Multi-class 분류문제에 적합하며 주로 softmax함수를 사용한다.  
    ![image](https://user-images.githubusercontent.com/71866756/151287257-1820801b-a197-46e3-9819-c98fb3e142a8.png)  

------

### No.13

**Association Rule의 Support, Confidence, Lift에 대해 설명해주세요.**

> Association Rule 정의
> 

어떤 사건이 얼마나 자주 함께 발생하는지, 서로 얼마나 연관되어 있는지를 표시하는 것을 **Association Rule**이라고 한다.

> Association Rule의 3가지 척도
> 

1️⃣ Support

→ Support는 **전체 경우의 수에서 두 아이템이 같이 나오는 비율**을 의미한다. (= 관계를 설정하기 위한 상품들이 **동시에 발생**될 확률)

<img src="https://blog.kakaocdn.net/dn/bWLbXX/btqw8CVCn9h/UY4ObQTdMTsYasgbdy7np0/img.jpg" width="50%" height="50%">

- N : 전체 경우의 수
- ![image](https://user-images.githubusercontent.com/90603530/151339487-9ae8e390-ec07-430e-8cbb-23c5e5accf86.png) : x와 y가 동시에 일어난 경우의 수

ex. 차와 라떼를 주문한 고객이 머핀을 주문할 support 값?

<img src="https://blog.kakaocdn.net/dn/er9hMT/btqw7O3ffQ1/3cxMHPPhKCp6U51cyStQck/img.jpg" width="50%" height="50%">

차, 라떼, 머핀을 동시에 구매한 경우의 수를 전체 경우의 수로 나눈 값이 support가 된다.

→ support는 **x와 y의 순서를 바꾸어도 결과가 똑같이 나온다**. 

ex. 머핀을 주문한 고객이 차와 라떼를 주문할 support 값도 위 식과 똑같이 계산할 수 있다. 

→ Support 값은 **높으면 높을수록 관계가 더 의미**있다고 할 수 있다.

📌 support의 역할 - 발생 빈도

**얼마나 자주 발생되는지 측정**해 줍니다. 만약 Support값이 매우 낮다면 그 아이템은 낮은 확률로 선택되었음을 의미합니다. Support를 통해 우리는 로그에서 특정 로그가 우연히 발생된건지 아니면 일반적으로 발생된건지 측정할 수 있습니다.

2️⃣ Confidence

→ Confidence는 **X가 나온 경우 중 X와 Y가 함께 나올 비율**을 의미한다. (= **특정 상품이 선택된 뒤, 다른 상품이 선택될 확률**)

ex. 구매의 경우를 예로 들자면 X를 산 사람 중에 Y도 같이 사는 사람의 비율을 말한다. 

<img src="https://blog.kakaocdn.net/dn/0ObsV/btqxbACe59A/89Wew3zPpTAbFEVCrmKknk/img.jpg" width="50%" height="50%">

- ![image](https://user-images.githubusercontent.com/90603530/151339578-70fb3f06-25e3-4188-b983-03af7ef0aa16.png) : x가 나온 경우의 수
- ![image](https://user-images.githubusercontent.com/90603530/151339487-9ae8e390-ec07-430e-8cbb-23c5e5accf86.png) : x와 y가 동시에 일어난 경우의 수

ex. 차와 라떼를 주문한 고객이 머핀을 주문할 confidence 값?

<img src="https://blog.kakaocdn.net/dn/kFskg/btqxaEytiZm/vUqKuw60D4OB4Kl6c5Tt00/img.jpg" width="50%" height="50%">

→ Confidence 값은 **1에 가까울수록 관계가 더 의미**있다고 할 수 있다.

📌 confidence의 역할 - 순서

아이템 간의 발생 순서를 고려하기 때문에 **predictability (예측 가능성)을 결정**할 수 있습니다. 만약 특정 아이템 간의 Confidence가 매우 낮다면 일시적으로 발생된 이벤트 시퀀스를 의미하며 정상적인 경우에는 잘 나타나지 않는 발생 순서임을 알 수 있습니다.

3️⃣ Lift

→ Lift는 **X와 Y가 같이 나오는 비율을 X가 나올 비율과 Y가 나올 비율의 곱으로 나눈 값**이다. 

<img src="https://blog.kakaocdn.net/dn/b3wY5u/btqxcMJcChs/ypoO0OsCxsFMibPbLHMqhk/img.jpg" width="50%" height="50%">


ex. 차와 라떼를 주문한 고객이 머핀을 주문할 lift 값? 

<img src="https://blog.kakaocdn.net/dn/bqOVoo/btqw7QGNgig/40UC3ukZfcpo8EZv3995Ik/img.jpg" width="50%" height="50%">

→ Lift 값은 **1보다 높을 때 positively correlation, 1일 때 independent, 1보다 작을 때 negatively correlation**이라고 여긴다. ⇒ lift 값을 **1보다 높은 값을 가질 때 관계가 의미**있다고 할 수 있다.

cf. 데이터 집합 T가 주어지고, min sup, min conf가 주어졌을 때, 만족하는 관계가 있는 rule을 찾는 알고리즘이 바로 Apriori 알고리즘 입니다.

References 

- [Association Rule (연관 규칙)이란? - 유니의 프로세스마이닝 공부 (tistory.com)](https://process-mining.tistory.com/34)
- [[Data Mining] 1.1. 연관 법칙 (Association Rule) 소개 (hackability.kr)](https://hackability.kr/entry/Data-Mining-11-%EC%97%B0%EA%B4%80-%EB%B2%95%EC%B9%99-Association-Rule-%EC%86%8C%EA%B0%9C)

---

### No.14

**최적화 기법중 Newton’s Method와 Gradient Descent 방법에 대해 알고 있나요?**

> Newton’s Method
> 

함수의 해(= y좌표의 값이 0이 되도록 하는 x좌표의 값)를 근사하는 방법의 하나이다.

1️⃣ 임의의 x 를 정한다.

2️⃣ f(x)값이 0인지 확인한다.

→ 0이라고 해도 될 정도로 작은 값이면 종료

→ 0이라고 할 수 없는 값이면 3️⃣으로 진행                                 
3️⃣ f(x)의 접선을 그린다.

4️⃣ 접선과 x축이 만나는 지점으로 x를 옮긴다.

5️⃣ 과정2️⃣~4️⃣를 반복해서 f(x) = 0 인 지점을 찾는다.

<img src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/6a99ea48-fd83-4443-94b9-4f1d6d012893/NewtonIteration_Ani.gif?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220127%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220127T100325Z&X-Amz-Expires=86400&X-Amz-Signature=038dfaa496a4784b04ff88382e5ab9c42d4d7dad3ce7fea2aa8c1a9db6f6666b&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22NewtonIteration_Ani.gif%22&x-id=GetObject" width="50%" height="50%">

> Newton’s Method 수식
> 

<img src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/14cfd7c3-9d0b-48fb-b329-873b464847f0/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220207%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220207T051653Z&X-Amz-Expires=86400&X-Amz-Signature=8e028fcd3c0167622bbdd0214ae6ef0154789ed88e5c50b76154640f81407cf3&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject" width="100%" height="100%">

위의 식을 이용해서 ![image](https://user-images.githubusercontent.com/90603530/151339725-b838a5f4-d885-4dbb-ab79-dee8c6b1ad33.png) 근사하는 방법을 Newton’s Method라고 한다.

📎 수식 설명

x=t에서 접선의 방정식을 구하고, 이 접선의 x절편의 값을 구하자

<img  src="https://user-images.githubusercontent.com/90603530/151494039-092fefbb-920e-412d-bf59-86b6ec612311.png" width="30%" height="30%">

위의 식에서 나온 ![image](https://latex.codecogs.com/png.image?\dpi{110}&space;x)는 Newton’s Method의 과정을 거치며 ![image](https://latex.codecogs.com/gif.latex?f%28x%29)의 해인 ![image](https://latex.codecogs.com/gif.latex?%7B%5Cdisplaystyle%20%7B%5Chat%20%7Bx%7D%7D%7D)로 근사한다.

→ ![image](https://latex.codecogs.com/gif.latex?f%27%28x%29%3D0)을 이용하면 최솟값 또는 극솟값을 찾을 때도 Newton’s method를 사용할 수 있다. 

> Gradient Descent
> 

함수의 기울기를 구하고 경사의 절댓값이 낮은 쪽으로 계속 이동시켜 극값에 이를 때까지 반복시킨다. 

> Gradient Descent 수식
> 

최적화할 함수 ![image](https://latex.codecogs.com/gif.latex?%7B%5Cdisplaystyle%20f%28%5Cmathbf%20%7Bx%7D%20%29%7D)에 대하여, 먼저 시작점 ![image](https://latex.codecogs.com/gif.latex?%7B%5Cdisplaystyle%20%5Cmathbf%20%7Bx%7D%20_%7B0%7D%7D)를 정한다. 현재 ![image](https://latex.codecogs.com/gif.latex?%7B%5Cdisplaystyle%20%5Cmathbf%20%7Bx%7D%20_%7Bi%7D%7D)가 주어졌을 때, 그 다음으로 이동할 점인 ![image](https://latex.codecogs.com/gif.latex?%7B%5Cdisplaystyle%20%5Cmathbf%20%7Bx%7D%20_%7Bi&plus;1%7D%7D)은 다음과 같이 계산된다.

<img src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/9c998f5c-44c6-4ffb-ab82-7c3d6a5f3271/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220207%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220207T051805Z&X-Amz-Expires=86400&X-Amz-Signature=9e2a603d7f8a9f975ac23c8c53b09fb0351e61560d8b09f31af583a4dc38beb8&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject" width="50%" height="50%">

이때 ![image](https://latex.codecogs.com/gif.latex?%7B%5Cdisplaystyle%20%5Cgamma%20_%7Bi%7D%7D)는 이동할 거리를 조절하는 매개변수이다. 이 알고리즘의 수렴 여부는 *f*의 성질과 ![image](https://latex.codecogs.com/gif.latex?%7B%5Cdisplaystyle%20%5Cgamma%20_%7Bi%7D%7D)의 선택에 따라 달라진다. 또한, 이 알고리즘은 극소점으로 수렴한다.

> Newton’s method와 Gradient Descent
>

<img src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/8dd3f8c9-c2c7-452c-8d6b-2255c65a4272/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220207%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220207T051825Z&X-Amz-Expires=86400&X-Amz-Signature=e0d9ac078726f514143cbbc744228d106c2b33d0ce2712ff2edc757ab3f0a858&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject" width="50%" height="50%">

📌 Gradient Descent

α를 사람이 설정하고 α만큼 기울기 방향으로 x값을 갱신한다. 

📌 Newton’s Method 

2차 미분을 이용하여 경사하강법에서의 α(= 1 / f''(x))를 자동으로 조정한다. 

📌 Gradient Descent VS. Newton’s Method

Gradient Descent은 1차 미분의 정보만을 사용

↔ Newton’s Method은 2차 미분의 정보도 활용하므로 목적지에 더 빨리 도달할 가능성이 높다. 

물리 세계로 보면 뉴턴 방법은 속도뿐만 아니라 가속도 정보까지 사용하기 때문이다.

References

- [뉴턴 방법 - 위키백과, 우리 모두의 백과사전 (wikipedia.org)](https://ko.wikipedia.org/wiki/%EB%89%B4%ED%84%B4_%EB%B0%A9%EB%B2%95)
- [뉴턴법(Newton's method) ,가우스-뉴턴법(Gauss-Newton Method) : 네이버 블로그 (naver.com)](https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=tlaja&logNo=220731745142)
- [Newton Method(뉴턴법) (tistory.com)](https://hip-studyrecord.tistory.com/31)
- [경사 하강법 - 위키백과, 우리 모두의 백과사전 (wikipedia.org)](https://ko.wikipedia.org/wiki/%EA%B2%BD%EC%82%AC_%ED%95%98%EA%B0%95%EB%B2%95)
- [경사하강법(gradient descent) - 공돌이의 수학정리노트 (angeloyeo.github.io)](https://angeloyeo.github.io/2020/08/16/gradient_descent.html)
- [28~29단계) 경사하강법 , 뉴턴 방법 , 함수 최적화 (tistory.com)](https://amber-chaeeunk.tistory.com/62)

---

### No.15

**머신러닝(machine)적 접근방법과 통계(statistics)적 접근방법의 둘간에 차이에 대한 견해가 있나요?**

**사용하는 목적**에서 차이가 발생한다 

> 머신러닝적 접근 방법
> 

**예측의 성공 확률을 높이는 데**에 목적이 있다. 따라서 모델의 신뢰도나 정교한 가정은 상대적으로 중요성이 낮아지며, 과적합을 감안해서라도 여러 feature를 사용해 예측을 수행한다.

ex. 카드결제이력을 바탕으로 특정 고객군의 지출을 예측한다면 고객정보, 기온, 가맹점 특성 등 최대한의 feature를 모델에 적용해 예측을 수행하며, 어떤 feature가 왜 중요한지는 크게 중요하지 않게 된다.

> 통계적 접근 방법
> 

분포나 가정을 통해 **실패 확률을 줄이는 데**에 목적이 있다. 따라서 모형의 복잡성보다는 단순성을 추구하며, 신뢰도가 중요해진다. 추가적으로 파라미터의 해석가능성 또한 통계분석 방법에서는 중요하게 다뤄진다. 

ex. 특정 고객군 지출 예측 시 중요 feature를 미리 선택하여 고객이 왜 해당 지출을 하는지에 대한 설명이 가능해지도록 분석이 이루어지는 것이다.

References

[Machine Learning과 전통적 통계분석 방법의 차이 - Eunkyung’s github Blog (ek-koh.github.io)](https://ek-koh.github.io/data%20analysis/ML-diff/)"

------

### No.16

**인공신경망(deep learning이전의 전통적인)이 가지는 일반적인 문제점은 무엇일까요?**

deep neural network 이전의 인공신경망이라고 하면 **회귀 모델**을 생각할 수 있으며, 회귀 모델의 문제점은 대표적으로

- **문제점 1 : 단층 퍼셉트론으로 XOR 문제를 해결할 수 없다.** 

  선형 회귀 모델이란, 선형 함수로  예측을 수행하는 회귀용 선형 알고리즘입니다. 

  이름에서 알 수 있다시피 선형 함수를 통해 예측을 하기 때문에, 여러 layer를 쌓는 것은 무의미하며, 단층 퍼셉트론으로 구성하게 됩니다. 

  그리고 이러한 단층 퍼셉트론으로는 XOR 문제를 해결할 수 없다는 문제를 일으키게 됩니다. 

- **문제점 2 : 실제 데이터를 정확히 반영하지 못한다.** 

  선형 회귀 모델은 **독립 변수** 간 서로 선형적으로 **독립**임을 **가정**하고, 독립변수와 종속변수는 선형관계임을 가정합니다. 

  하지만, 실제 데이터에서 이러한 가정은 대부분 옳지 않으며, 그렇기에 전통적인 인공신경망의 경우 실제 데이터를 정확히 반영하지 못한다는 문제점이 있습니다.

    

[**References**]

[딥러닝의 개요-퍼셉트론](https://zsunn.tistory.com/13)

------

### No.17

**지금 나오고 있는 deep learning 계열의 혁신의 근간은 무엇이라고 생각하시나요?**

- **빅데이터**

  이전 AI에서는 전체적인 데이터의 부족으로 인해 더 깊은 모델을 구성하기에도 어려웠으며, 학습을 하더라도 제한된 레이블로 실제 비즈니스 분야에 적용하는데 많은 어려움이 있었습니다. 

  하지만, 2012년, **ImageNet**을 통해 Computer Vision분야에서 획기적인 발전을 이룰 수 있었습니다.

  이러한 대량의 데이터셋을 이용하여 깊고 넓은 모델을 학습하면서 좋은 성능을 낼 수 있었습니다. 

- **하드웨어의 발전**

  일반적인 CPU 시스템보다 30배 이상 연산속도가 빠른 GPU의 발전으로 좀 더 복잡하고 깊은 신경망을 구성하여 학습시킬 수 있게 된 것이 deep learning의 발전에 기여를 했다고 생각합니다.   

------

### No.18

**ROC 커브에 대해 설명해주실 수 있으신가요?**

- **ROC curve**

  ![image](https://user-images.githubusercontent.com/71866756/152736895-9936063a-d455-4be6-a7ec-cd1c20de1824.png)

  - `ROC 커브`란 Receiver operating characteristic의 약자로, 머신러닝 모델을 평가할 때 사용되는 지표입니다.

  - x축은 `FPR`, y축은 `TPR`로 각각 0, 1일 때가 가장 이상적인 경우입니다.   

  - `AUC`가 넓을수록 좋은 성능을 의미합니다. 

    ( Positive로 예측한 값들 중, 실제 Positive인 값이 Negative보다 많아야 `AUC`가 넓다. ) 



![image](https://user-images.githubusercontent.com/71866756/152736879-a025a7d7-8e22-483b-b254-0b01736ce1d1.png)

![image](https://user-images.githubusercontent.com/71866756/152736865-b453013b-2055-4e4b-be7f-6a75501af8a0.png)

> `FPR (False Positive rate)` : FPR = FP/(FP+FN)로 표현이 가능하며, 실제로는 음성이지만, 양성으로 잘못 판정한 경우의 비율을 의미합니다. 
>
> `TPR (True Positive rate)` : TPR = TP/(TP+TN)로 표현이 가능하며, 실제로는 양성이면서, 양성으로 잘 판정한 경우의 비율을 의미합니다. 
>
> `AUC (Area Under the Curve)` : curve의 아래 면적을 의미합니다. 

- **ROC curve 추정 방법**

  ![image](https://user-images.githubusercontent.com/71866756/152736850-a938b4bd-f187-4419-a207-12a53ce76829.png)

  ( 위 그림에서 각각의 예측 확률은 Positive로 예측할 확률을 의미한다. )

  > Step1) Threshold 값을 정한다.
  >
  > Step2) Threshold 값에 따른 모델의 예측을 측정한다. 
  >
  > ​			(Threshold가 0.7일 경우, 예측 확률이 0.7 이상인 것만 Positive로 예측)
  >
  > Step3) x = FPR과 y = TPR을 수식에 맞춰서 계산한다.  
  >
  > Step4) (x,y)로 plot한다. 
  >
  > Step5) Threshold값을 낮추면서 Step1~4를 반복한다. 



[**References**]

[ROC (Receiver Operating Characteristic) Curve  완벽 정리](https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=sw4r&logNo=221015817276)

[ROC curve란?](https://losskatsu.github.io/machine-learning/stat-roc-curve/#3-roc-%EC%BB%A4%EB%B8%8C)

---

### No.19

**여러분이 서버를 100대 가지고 있습니다. 이때 인공신경망보다 Random Forest를 써야하는 이유는 뭘까요?**

Random forest는 ensemble(앙상블) machine learning 모델이다. 데이터가 여러개의 독립적인 decision tree를 통과하고, 각각의 decision tree가 분류한 결과를 투표하는 형식이므로 다수의 서버에서 병렬적인 처리가 가능하다.

<img src="https://user-images.githubusercontent.com/63924704/152754277-d52ef65a-92e8-4e28-929d-a1b1b35c059b.png" width=400>

반면, 일반적으로 데이터의 input-output까지 한번에 처리하는 end-to-end 인공신경망은 직렬적인 구조로 구성된다.

[**References**]

[Random Forest(랜덤 포레스트) 개념 정리](https://eunsukimme.github.io/ml/2019/11/26/Random-Forest/)

[Interview Question & Answer](https://yongwookha.github.io/MachineLearning/2021-01-29-interview-question)

---

### No.20

**K-means의 대표적 의미론적 단점은 무엇인가요? (계산량 많다는것 말고)**

K-means는 비슷한 속성을 가진 데이터끼리 묶어주는 군집화 알고리즘이다. K-means 알고리즘은 다음의 절차로 진행된다.

1. k값 설정 - 몇 개의 그룹으로 군집화할 것인지 설정한다.
2. 데이터 안에서 k개의 데이터를 랜덤으로 샘플링한다. 이를 centroids라고 한다.
<img width="410" alt="1" src="https://user-images.githubusercontent.com/63924704/152755488-0b4e6a19-6027-44af-970e-6077b743325f.png">


3. 나머지 데이터에 대해, 가장 가까운 centroids 그룹으로 묶어준다. 아래에서는 k1, k2, k3 중심점에 가까운 점들이 각각 초록색, 빨간색, 남색으로 묶였다.
<img width="406" alt="2" src="https://user-images.githubusercontent.com/63924704/152755567-351a053a-3fc1-4349-94dd-e318858f67de.png">


4. 각 그룹별로 평균을 계산해 centroids를 이동한다.
<img width="410" alt="3" src="https://user-images.githubusercontent.com/63924704/152755648-513f1420-6a3a-4dc2-b65b-9a9d3761a2fa.png">


5. centroids가 더이상 움직이지 않을 때까지 3-4의 과정을 반복한다.

</br>

**K-means 알고리즘의 단점**은 다음과 같다.

- 초기 설정 클러스터 수(k)가 적합하지 않으면 결과가 좋지 못하다.
- 클러스터 중심(centroids)을 초기에 랜덤하게 위치시키기 때문에, 매번 결과가 달라질 수도 있다.

[**References**]

[K-means Clustering (K-평균 군집화)이란? (K-means clustering의 장단점)](https://process-mining.tistory.com/122)
[K-Means 클러스터링 쉽게 이해하기](https://hleecaster.com/ml-kmeans-clustering-concept/)
[Random Initialization](https://wikidocs.net/4693)

---

### No.21

**L1, L2 정규화에 대해 설명해주세요.**

`정규화`는 모델의 과적합(Overfitting) 문제를 완화해주는 방법론 중 하나이다. 즉, 모델의 일반화 성능을 높이고자 하는 목적을 갖고 있다. 정규화 외에도 data augmentation, drop-out, (model) ensemble 등 여러가지 방법들이 존재한다.

이때, 정규화 방법에는 대표적으로 L1 정규화와 L2 정규화가 있다. 두 정규화는 모델 학습시에 값이 너무 큰 파라메터의 영향력을 줄이는 역할을 한다. L1 정규화는 Cost Function에 가중치의 크기(절대값)를 더해주고, L2 정규화는 가중치 크기의 제곱을 더해줌으로써 가중치가 너무 크지 않은 방향으로 학습을 유도한다. 

이러한 두 정규화 방식에는 선형대수학의 norm 개념이 적용되었기 때문에, norm을 기준으로 두 정규화 방식의 차이를 알아보자.

> Norm이란 어떤 벡터의 크기를 의미한다. 즉, 모든 원소의 절댓값의 합(L1-norm) 혹은 제곱의 합(L2-norm)으로 벡터를 하나의 숫자로 나타내어, 벡터간 크기 비교가 가능하게끔 하는 것이다. 

이러한 개념을 통해 머신러닝에서 모델의 복잡도를 L1-norm과 L2-norm을 통해 하나의 숫자로 표현할 수 있게 된다. 하나의 숫자로 표현된 모델의 복잡도를 loss 함수에 추가하여,  기존의 loss를 최소화함과 동시에 모델의 복잡 역시 낮추는 방향으로 학습을 시키는 것이다. 수식은 아래와 같다.

<img src="https://latex.codecogs.com/svg.image?\text{Loss}_{\text{L1-reg}}&space;=&space;\text{Error}(y,&space;\hat&space;y)\;&space;&plus;&space;\;&space;\lambda&space;\sum_i^N&space;|w_i|&space;\\&space;\text{Loss}_{\text{L2-reg}}&space;=&space;\text{Error}(y,&space;\hat&space;y)\;&space;&plus;&space;\;&space;\lambda&space;\sum_i^N&space;w_i^2&space;\\" title="\text{Loss}_{\text{L1-reg}} = \text{Error}(y, \hat y)\; + \; \lambda \sum_i^N |w_i| \\ \text{Loss}_{\text{L2-reg}} = \text{Error}(y, \hat y)\; + \; \lambda \sum_i^N w_i^2 \\" />

<img src="https://latex.codecogs.com/svg.image?\lambda" title="\lambda" />를 낮출수록 규제항의 영향력이 작아진다. 

</br>

**L1, L2 정규화의 차이**

모델의 가중치를 업데이트 할 때, Loss function을 미분하기 때문에 위의 두 식을 미분했을 때를 생각해보면 된다.

**L1 정규화**의 경우에는 가중치의 크기에 상관없이 상수값(<img src="https://latex.codecogs.com/svg.image?\lambda" title="\lambda" />)을 빼주는 식으로 W를 업데이트하게 된다. (<img src="https://latex.codecogs.com/svg.image?\frac{d|x|}{dx}&space;=&space;\frac{x}{|x|}" title="\frac{d|x|}{dx} = \frac{x}{|x|}" />)

이는 W의 어떤 값 <img src="https://latex.codecogs.com/svg.image?w_i" title="w_i" /> 를 0이 되도록 한다. 즉, 업데이트가 진행되면서 중요한 가중치만을 취하기 때문에 feature selection의 효과가 있다. 영향을 크게 미치는 핵심적인 피처들만 반영하도록 하는 것이다.

**L2 정규화**의 경우에는 loss를 미분했을 때 규제항이 <img src="https://latex.codecogs.com/svg.image?2\lambda&space;W" title="2\lambda W" /> 의 값을 갖는다. 업데이트 시 가중치의 값 자체를 고려한다는 것이다. 이는 튀는 값(outlier)에 대해 L1 정규화보다 민감하게 반응하므로, 이상치나 노이즈가 있는 데이터에 대한 학습을 진행할 때 사용하면 좋다.

</br>

[**References**]

[L1, L2 Norm, Loss, Regularization?](https://junklee.tistory.com/29)  
[선형대수학 Norm, L1 L2 Regularization](https://www.youtube.com/watch?v=deEqfwlH67U)  
[L1, L2 규제(또는 정규화, Regularization)](https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=sky3000v&logNo=221536661344)  
[L1, L2 Regularization (Lasso, Ridge)](https://dailyheumsi.tistory.com/57)  

---
### No.22
**Cross Validation은 무엇이고 어떻게 해야하나요?**

- Cross Validation(교차검증)이란?  
  보통은 train set으로 모델을 훈련하고 test set으로 모델을 검증한다. 하지만 고정된 test set을 통해 모델의 성능을 검증하고 수정하는 과정을 반복하면, 결국 내가 만든 모델은 test set에만 잘 동작하는 모델이 된다. 즉, **test set에 과적합(overfitting)하게 되므로, 다른 실제 데이터를 가져와 예측을 수행하면 엉망인 결과가 나와버리게 된다.** 따라서 이를 해결하고자 하는 것이 바로 **Cross Validation**이다. Cross Vlidation은 train set을 **train set**과 **validation set**으로 분리한 뒤, **validation set**을 사용해 검증하는 방식이다.

- Cross Validation의 종류는?
  - Holdout Cross Validation : 홀드 아웃 교차 검증
    - 전체 데이터를 비복원 추출 방법을 이용하여 랜덤하게 train set과 validation set으로 나눠 검증하는 기법 <p align='center'><img src="https://user-images.githubusercontent.com/57162812/152996147-dd1f34bf-8b22-400e-a650-06b8ff010650.png" width=350></p>

    - 장점 : iteration을 1번만 해서 계산 시간 부담이 적다.
    - 단점 : 전체 데이터에서 Validation set은 학습에 사용할 수 없으므로 데이터 손실이 발생한다. 또한, 데이터를 어떻게 나누느냐에 따라 결과가 많이 달라질 수 있다.
  - K-Fold Corss Validation
    - 데이터 집합을 무작위로 동일 크기를 갖는 K개의 부분집합으로 나누고, 그 중 1개의 집합을 Validation set으로, 나머지 (K-1)개 집합을 Train set으로 선정하는 분석 모형을 평가하는 기법! <p align='center'><img src="https://user-images.githubusercontent.com/57162812/152996661-dc634679-50c4-492a-9dc4-a8e9a1cbe2cd.png" width=350></p>
    - K번 반복 수행하며, 결과를 K에 다수결 또는 평균으로 분석한다.
  - Leave-One-Out Cross Validation : LOOCV
    - 전체 데이터 N개에서 1개의 샘플만을 평가 데이터에 사용하고 나머지 (N-1)개는 훈련 데이터로 사용하는 과정을 N번 반복하는 교차 검증 기법이다.
    - K-Fold와 같은 방법을 사용하며, 이 때 K는 전체 데이터 N과 같다.(K=N)! <p align='center'><img src="https://user-images.githubusercontent.com/57162812/152998022-441da175-18f4-4968-99f0-4702a494ed08.png" width=400></p>
  - Leave-p-Out Cross Validation : LpOCV
    - LOOCV에서 1개의 샘플이 아닌 p개의 샘플을 테스트에 사용하는 교차 검증 기법이다.
    -  <img src="https://latex.codecogs.com/svg.image?_nC_p" />만큼 교차 검증이 반복된다.

- Cross Validation의 장점과 단점은?
  - 장점
    - 모든 데이터 셋을 평가에 활용하여 특정 데이터셋에 대한 **과적합 방지**
    - 모든 데이터 셋을 훈련에 사용하여 **더욱 일반화된 모델 생성** 가능
  - 단점
    - iteration 횟수가 많기 때문에 **모델 훈련/평가 소요시간 증가**

[**References**]  
[[ML] 교차검증 (CV, Cross Validation) 이란? - 우노](https://wooono.tistory.com/105)  
[교차검증 Cross Validation - 서경](https://jerryk026.tistory.com/52)  
[Holdouts and Cross Validation: Why the Data Used to Evaluate your Model Matters](https://community.alteryx.com/t5/Data-Science/Holdouts-and-Cross-Validation-Why-the-Data-Used-to-Evaluate-your/ba-p/448982)  
[빅데이터 분석기사 필기 수제비2022]

---
### No.23
**XGBoost을 아시나요? 왜 이 모델이 캐글에서 유명할까요?**

`XGboost(Extreme Gradient Boosting)`는 앙상블의 부스팅 기법의 한 종류이다. 이전 모델의 오류를 순차적으로 보완해나가는 방식으로 모델을 형성한다. 즉, 이전 모델에서의 실제값과 예측값의 오차를 훈련 데이터에 투입하고 gradient를 이용하여 오류를 보완하는 방식을 사용한다.

Regression, Classification 문제를 모두 지원하며, 성능과 효율이 좋아 인기 있게 사용되는 알고리즘이다. 또한, Kaggel 경연대회에서 상위를 차지한 많은 과학자들이 XGBoost를 이용하면서 널리 알려졌다.

GBM에 기반하고 있지만, GBM의 단점인 느림 수행시간 및 과적합 규제의 부재 등의 문제를 해결해서 각광받고 있다.

**XGBoost의 장점**
1. 분류와 회귀영역에서 뛰어난 예측 성능 발휘
2. 분류와 회귀영역에서 뛰어난 예측 성능을 발휘한다.
3. XGBoost는 병렬처리를 사용하여, GBM 대비 빠른 수행시간을 보인다.
4. Regularization, Early Stopping 기능을 통해 오버피팅을 방지할 수 있다.
5. Tree Pruning(가지치기) 제공한다. 미리 정해둔 max_depth까지만 split하고 pruning을 하고, 거꾸로 올라가면서 positive gain이 없는 노드를 삭제한다.
6. 자체적으로 결측치를 처리해준다.
7. 매 iteration마다 교차검증을 수행한다.


[**Reference**]  
[[ML] XGBoost 개념 이해 - 우노](https://wooono.tistory.com/97)

---

### No.24
**앙상블 방법엔 어떤 것들이 있나요?**

`앙상블(Ensemble)`은 여러가지 동일한 종류 또는 서로 상이한 모형들의 예측/분류 결과를 종합하여 최종적인 의사 결정에 활용하는 기법이다.

앙상블의 특징은 다음과 같다.
1. 보다 높은 신뢰성 확보  
    다양한 모형의 예측 결과를 결합함으로써 단일 모형으로 분석했을 때보다 높은 신뢰성을 가진다.
2. 정확도(Accuracy) 상승  
    이상값에 대한 대응력이 높아지고, 전체 분산을 감소시킨다.
3. 원인분석에 부적합  
    모형의 투명성이 떨어지게 되어 정확한 현상의 원인분석에는 부적합하다.

- 배깅(Bagging)
  - Bootstrap Aggregation의 약자로 다수의 부트스트랩 자료를 생성하고, 각 자료를 모델링한 후 결합하여 최종 예측 모형을 만드는 알고리즘!<p align='center'><img src="https://user-images.githubusercontent.com/57162812/153003709-74d62e04-ac45-47fb-a58d-d5419ca41ca1.png" width=350></p>
  - Categorical Data는 투표방식(Voting)으로 결과를 집계하며, Continuous Data는 평균으로 집계한다.
  - 주요 알고리즘은 Random Forest이다. `Random Forest`는 부트스트랩을 통해 조금씩 다른 훈련 데이터에 대해 훈련된 기초 분류기들을 결합시키는 알고리즘이다.

- 부스팅(Boosting)
  - 잘못 분류된 개체들에 가중치를 적용, 새로운 분류 규칙을 만들고, 이 과정을 반복해 최종 모형을 만드는 알고리즘이다.
  - 예측력이 약한 모형들을 결합하여 강한 예측 모형을 만드는 방법이다.<p align='center'><img src="https://user-images.githubusercontent.com/57162812/153004976-7ce8bb67-ae54-4ad9-89bb-06921d4b1e02.png" width=400></p>
  - 주요 알고리즘은 AdaBoost(Adaptive Boost)와 GBM(Gradient Boost Machine)이 있다. `AdaBoost`는 잘못 예측한 데이터에 가중치를 부여하여 오류를 개선하는 알고리즘이며 `GBM`은 경사 하강법을 이용하여 가중치를 업데이트하여 최적화된 결과를 얻는 알고리즘이다.

- 배깅 vs. 부스팅
  - 배깅은 병렬로 학습하는 반면, 부스팅은 순차적으로 학습한다.
  - 부스팅은 배깅에 비해 성능이 좋다. 하지만 속도가 느리고 Overfitting의 가능성이 있다.
  - 개별 결정 트리의 낮은 성능이 문제라면 부스팅이 적합하고, 오버 피팅이 문제라면 배깅이 적합하다.

- 스태킹(Stacking)
<p align='center'><img src="https://user-images.githubusercontent.com/57162812/153008886-e6820c0b-b7bb-45f0-84f9-be62cbeb3211.png" width=400></p>

  - **Meta Modeling**이라고 불리기도 하는 이 방법은 "Two heads are better than one"이라는 아이디어에서 출발한다.
  - 개별적인 여러 알고리즘을 서로 결합해 예측 결과를 도출한다는 점에서 배깅 및 부스팅과 공통점을 가지고 있다.
  - 하지만 가장 큰 차이점은 개별 알고리즘으로 예측한 데이터를 기반으로 다시 예측을 수행한다는 것이다. 즉, **개별 모델을 통해 한 번 예측하고 그 예측한 결과를 다시 학습 데이터와 테스트 데이터로 나누어서 다시 예측하는 것**이다.
  - 스태킹에는 두 종류의 모델이 필요하다.
    - **개별 기반 모델**
    - 개별 기반 모델의 예측 결과를 학습 데이터로 만들어서 학습하고 예측하는 **최종 메타 모델**

[**References**]  
[배깅(Bagging)과 부스팅(Boosting) - 머신러닝 - 귀퉁이 서재](https://bkshin.tistory.com/entry/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-11-%EC%95%99%EC%83%81%EB%B8%94-%ED%95%99%EC%8A%B5-Ensemble-Learning-%EB%B0%B0%EA%B9%85Bagging%EA%B3%BC-%EB%B6%80%EC%8A%A4%ED%8C%85Boosting)  
[Bagging과 Boosting 그리고 Stacking](https://swalloow.github.io/bagging-boosting/)  
[앙상블 학습 (Ensemble Learning) - Stacking](https://casa-de-feel.tistory.com/9)  


---

### No.25

**feature vector란 무엇일까요?**

예를 들어, 어떤 한 대상을 숫자 또는 범주형 특성으로 표현하자면 다음과 같이 표현할 수 있습니다.

|         | 동물(1) 식물(2) | 귀여운가? | 나이(month) | 평판(1:좋음~5:안좋음) |
| ------- | --------------- | --------- | ----------- | --------------------- |
| 🦆부덕이 | 1               | 1(True)   | 1           | 1                     |

이를 통해 <img src="https://latex.codecogs.com/svg.image?x_booduck&space;=&space;[1,&space;1,&space;1,&space;1]" title="x_booduck = [1, 1, 1, 1]" /> 로 표현하면 대상을 수학적으로 계산하고 분석하기 쉬워지게 됩니다. 이런 방식의 표현법을 feature vector로 부르며, 어떤 대상을 feature vector로 표현하였을 때, 특정 차원의 feature map에 공간적으로 표현하고, 공간 상의 거리값을 기반으로 분류(classification), 회귀(regression), 군집화(clustering) 등의 계산을 수행할 수 있습니다.

  참고문헌

  - BRILLIANT Math & Science Wiki "[Feature Vector](https://brilliant.org/wiki/feature-vector/)"

---

### No.26

**좋은 모델의 정의는 무엇일까요?**

좋은 모델을 선택할 때 고려해야하는 사항들로는 대략 **정확성(accuracy)**, **속도(speed)**과 **크기(size)** 정도가 있습니다.

좋은 모델은 학습 데이터로부터 특징을 잘 학습하여 테스트 데이터에 대해 적용합니다. 데이터의 특징을 잘 추출해내기 위해 수많은 선행연구들이 진행되어 왔으며, 모델의 구조(architecture), 손실 함수(loss), 최적화 함수(optimizer)와 도메인 지식에 의한 기타 기법들이 개발되었습니다. 대다수의 프로젝트들은 오픈소스 또는 논문의 형태로 공개되어 있어 실생활에서 사용 가능하며, 대다수의 모델들은 이미 좋은 정확성을 자랑합니다.

하지만 실무에서는 모델의 실행 및 학습 속도와 모델의 크기 또한 고려해야 합니다. AI 모델을 사용하려는 기업 또는 사용자의 환경에 따라서, 정확성은 매우 뛰어난 것으로 알려져 있지만 속도와 크기의 측면에서 사용 불가능한 모델이 있다면, 해당 모델을 좋은 모델이라고 단정짓기 어렵습니다.

모델에 대한 평가는 사용자와 환경에 따라 판단이 달라질 수 있으며, 사용 가능한 데이터의 종류 및 양, 학습 환경, 실행 환경 등 많은 요소들을 고려해야 합니다. 예를 들어, 리소스가 제한되어 있는 핸드폰에서 비젼 모델을 실행시켜야 한다면, 가볍고 빠른 MobileNet이 여타 다른 비젼 모델들 보다 좋은 모델로 고려될 수 있습니다.

  참고문헌

  - Mike Shi(towardsdatascience) "[4 Steps to Finding the Right Deep Learning Model](https://towardsdatascience.com/4-steps-to-finding-the-right-deep-learning-model-f35a9d7988b6)"

---

### No.27

**50개의 작은 의사결정 나무는 큰 의사결정 나무보다 괜찮을까요? 왜 그렇게 생각하나요?**

![decision_tree](http://i.imgur.com/ZKDnzOB.png)

의사결정나무는 주어진 데이터를 정보획득(information gain) 계산 기반으로 분류하여, 분류된 데이터의 불순도(impurity) 혹은 불확실성(uncertainty)이 감소하는 방향으로 학습을 진행하는 비모수적 모델입니다. 이를 위해 엔트로피(entropy) 또는 지니계수(Gini Index) 등의 지표가 사용됩니다. 모델의 시각화가 쉬운 편이며, 학습 알고리즘이 단순하여 빠르고, 정규화/표준화 등의 데이터 전처리가 필요 없으며, 연속형 및 범주형 변수가 혼합되어 있어도 작동 가능하다는 장점이 있습니다.

하지만 의사결정나무는 학습 데이터에 과대적합되는 경향이 있어 일반화 성능이 좋지 않은 것으로 알려져 있습니다. 이는 모델의 크기가 커질수록 심해지기 때문에 가지치기(pruning) 등의 기법으로 이를 방지하기도 합니다. 또한 불균형 데이터셋에 대하여 성능이 좋지 않은 것으로 알려져 있기도 합니다.

50개의 작은 의사결정나무를 사용하려면 이들을 배깅(bagging) 또는 부스팅(boosting) 방법으로 앙상블 하여 사용하여야 합니다. 배깅과 부스팅 모두 여러 작은 트리 모델들을 모아서 정확도를 높이는 방법으로, 배깅을 사용하는 모델로는 Random Forest, 부스팅을 사용하는 모델로는 XGBoost 등이 있습니다.

작은 의사결정나무들을 배깅하기 위해서는 데이터로부터 여러 개의 샘플들을 추출하고 해당 개수 만큼의 작은 의사결정나무를 학습시키는 것이 필요합니다. 통계적 무작위성에 기반하며 병렬화된 계산이 특징이며, 과대적합을 막아줍니다. 특히 분산을 줄이는 것에 초점이 맞추어져 있습니다.

작은 의사결정나무들을 부스팅한다는 것은 gradient boosting 알고리즘을 기반으로 어떤 작은 의사결정나무를 학습 시킬 때 이전에 학습된 의사결정나무의 결과를 반영한다는 것을 뜻합니다. 순차적인 계산이 특징이며, 적절한 하이퍼파라미터 튜닝이 동반된다면 좋은 정확도를 얻을 수 있습니다. 특히 편향을 줄이는 것에 초점이 맞추어져 있습니다.

  참고문헌

  - ratsgo 이기창 "[의사결정나무(Decision Tree)](https://ratsgo.github.io/machine%20learning/2017/03/26/tree/)"
  - Kelly Slatery(towardsdatascience) "[Decision Trees: Understanding the Basis of Ensemble Methods](https://towardsdatascience.com/decision-trees-understanding-the-basis-of-ensemble-methods-e075d5bfa704)"
  - StatQuest with Josh Starmer [Youtube Channel](https://www.youtube.com/c/joshstarmer) - Decision Trees, Random Forest, XGBoost 등 참고!

---
### No.28

**스팸 필터에 로지스틱 리그레션을 많이 사용하는 이유는 무엇일까요?**

<img src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/4f1b1f86-69c2-48b7-a91c-c791afc774c5/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220211%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220211T050134Z&X-Amz-Expires=86400&X-Amz-Signature=cb31d764f7b236f0c238ddc86b87df1a36cc30365b6d43ed6dfc042f5c362314&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject" width="50%" height="50%">

> **로지스틱 회귀**
> 

로지스틱 회귀(Logistic Regression)는 회귀를 사용하여 데이터가 어떤 범주에 속할 확률을 0에서 1 사이의 값으로 예측하고 그 확률에 따라 가능성이 더 높은 범주에 속하는 것으로 **분류**해주는 지도 학습 알고리즘이다. 0과 1사이 처럼 종속변수로 올수있는 값이 제한적이므로 분류 문제에 적합하다. 

스팸 메일 분류기에 로지스틱 회귀를 적용한다면, 어떤 메일을 받았을 때 그것이 스팸일 확률이 0.5 이상이면 spam(스팸 메일)으로 분류하고, 확률이 0.5보다 작은 경우 ham(필요한 메일)으로 분류하는 것이다. 

> **선형회귀 VS. 로지스틱 회귀**
>

학생들이 시험 성적에 따라서 합격, 불합격이 기재된 데이터가 있다고 가정하자. 시험 성적이 x라면, 합불 결과는 y이다. 이 데이터로부터 특정 점수를 얻었을 때의 합격, 불합격 여부를 판정하는 모델을 만들어 보자.

| score(x) | result(y) |
| --- | --- |
| 45 | 불합격 |
| 50 | 불합격 |
| 55 | 불합격 |
| 60 | 합격 |
| 65 | 합격 |
| 70 | 합격 |

위 데이터에서 합격을 1, 불합격을 0이라고 하였을 때 그래프를 그려보면 아래와 같다.

![https://wikidocs.net/images/page/22881/%EB%A1%9C%EC%A7%80%EC%8A%A4%ED%8B%B1%ED%9A%8C%EA%B7%80.PNG](https://wikidocs.net/images/page/22881/%EB%A1%9C%EC%A7%80%EC%8A%A4%ED%8B%B1%ED%9A%8C%EA%B7%80.PNG)

1️⃣ 이러한 점들을 표현하는 그래프는 알파벳의 S자 형태로 표현된다. 이러한 **x와 y의 관계를 표현**하기 위해서는 직선을 표현하는 함수가 아니라 **S자 형태로 표현할 수 있는 함수가 필요**하다. 직선을 사용할 경우 보통 분류 작업이 제대로 동작하지 않는다.

2️⃣ 이번 예제의 경우 실제값. 즉, 레이블에 해당하는 **y가 0 또는 1이라는 두 가지 값**만을 가지므로, 이 문제를 풀기 위해서 **예측값은 0과 1사이의 값을 가지도록 한다.** 0과 1사이의 값을 확률로 해석하면 문제를 풀기가 훨씬 용이하다. **최종 예측값이 0.5보다 작으면 0으로 예측했다고 판단하고, 0.5보다 크면 1로 예측했다고 판단한다.** 만약 **y=wx+b의 직선을 사용할 경우, y값이 음의 무한대부터 양의 무한대와 같은 큰 수들도 가질 수 있는데** 이는 직선이 분류 문제에 적합하지 않은 두번째 이유이다.

출력이 0과 1사이의 값을 가지면서 S자 형태로 그려지는 함수로 시그모이드 함수(Sigmoid function)가 있다. 로지스틱 회귀 모델은 활성화 함수로 시그모이드 함수를 사용한다. 

흔히 로지스틱 회귀는 종속변수가 **이항형 문제**(즉, 유효한 범주의 개수가 두개인 경우)를 지칭할 때 사용된다. 이외에, **두 개 이상의 범주**를 가지는 문제가 대상인 경우엔 **다항 로지스틱 회귀 (multinomial logistic regression) 또는 분화 로지스틱 회귀 (polytomous logistic regression)**라고 하고 **복수의 범주이면서 순서가 존재**하면 **서수 로지스틱 회귀 (ordinal logistic regression)** 라고 한다.

이 때, 스팸 분류 문제는 (스팸(1)/햄(0))으로 분류하므로 이항형 문제이다. 따라서, 로지스틱 회귀를 사용하는 것이 적합하다. 

### 참고

- [로지스틱회귀(Logistic Regression) 쉽게 이해하기 - 아무튼 워라밸 (hleecaster.com)](https://hleecaster.com/ml-logistic-regression-concept/)
- [5.3 분류모형 — 데이터 사이언스 스쿨 (datascienceschool.net)](https://datascienceschool.net/03%20machine%20learning/09.03%20%EB%B6%84%EB%A5%98%EB%AA%A8%ED%98%95.html)
- [[모델 선정] 이진분류 알고리즘 3가지 (퍼셉트론, 아달린, 로지스틱 회귀) (tistory.com)](https://hyjykelly.tistory.com/41)
- [[딥러닝] 선형회귀와 로지스틱회귀 :: Dev Log : 삶은 확률의 구름 (tistory.com)](https://ebbnflow.tistory.com/129)
- [[인공지능][개념] 로지스틱 회귀(Logistic Regression)는 무엇이며, 시그모이드(Sigmoid) 함수는 왜 사용하는 것일까? (tistory.com)](https://itstory1592.tistory.com/8)
- [05) 로지스틱 회귀(Logistic Regression) - 딥 러닝을 이용한 자연어 처리 입문 (wikidocs.net)](https://wikidocs.net/22881)

---  

### No.29     

**OLS(ordinary least squre) regression의 공식은 무엇인가요?**

> 단순 선형 회귀
> 

선형회귀는 결과변수 y와 원인변수 x의 선형 상관 관계를 모델링 하는 것이다.

즉, x값이 주어졌을때 이를 가장 잘 나타낼 수 있는 y값을 얻을 수 있는 모델링이다.

<img src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/bcb940a9-e441-4f31-ab8d-ee3580ac44ad/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220211%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220211T050456Z&X-Amz-Expires=86400&X-Amz-Signature=db39f427c9a9364394a562368e54411a426337ebceb8d5cb7f1280ffecb1afed&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject" width="50%" height="50%">


우리는 위와 같은 식을 가정할 수 있고, 데이터로부터 x값이 주어졌을때 **예측값**<img src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/bf765df9-b375-413f-9e16-a1e43ff0277c/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220211%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220211T050603Z&X-Amz-Expires=86400&X-Amz-Signature=f9ee0a65625cd2569106b61f8c80f149fbb17191078f9ad5c128e741d4ae7a26&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject" width="50%" height="50%">를 얻을 수 있다. 하지만 하나의 선으로 모든 y값을 정확히 나타낼 수 없기 때문에 우리가 예측한 <img src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/bf765df9-b375-413f-9e16-a1e43ff0277c/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220211%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220211T050603Z&X-Amz-Expires=86400&X-Amz-Signature=f9ee0a65625cd2569106b61f8c80f149fbb17191078f9ad5c128e741d4ae7a26&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject" width="50%" height="50%">와 **실제 데이터**<img src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/c4eba9d2-ecb7-46da-ba10-ae519bd059c7/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220211%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220211T050719Z&X-Amz-Expires=86400&X-Amz-Signature=2ecf97a13e628e6fa41b826668008c07252c6b8a4d6d0de3653b8d044d7b296e&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject" width="50%" height="50%">에는 차이가 존재한다. 이러한 차이를 **오차(Error)**라고 하며 **ϵ**으로 표기한다.



여기서 우리가 원하는 것은 해당 식에서 **오차가 가장 최소가 되도록 하는**(x값을 해당식에 대입했을때 예측되는 값과 실제 값의 차이가 최소가 되도록 하는) **β값과 α값을 찾는 것이다.**

> **OLS (**Ordinary Least Squares)**
> 

**오차의 제곱**을 최소화 하는 β와 α를 추정하는 방식이다.

- SSE란, Sum of Squared Error의 약자로 오차의 제곱값을 합한 것이다.

<img src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/ea18f4d7-3d6c-4e79-b523-ad3ca1987217/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220211%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220211T050840Z&X-Amz-Expires=86400&X-Amz-Signature=0c5fae0b751b62bcb4b3dd28ab174e53aaa3e7316ab7dae8d341bac67600c9b7&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject" width="50%" height="50%">

SSE를 최소화하는 α와 β를 찾아야 하므로, SSE를 각각 α와 β에 대해 미분한다. 

<img src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/619bc891-6e32-4aff-a1d6-831594cd9c16/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220211%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220211T050912Z&X-Amz-Expires=86400&X-Amz-Signature=ca54668c908391ecb5d6636c7d0bcdd650bc24e8044fe3700993baff5622a03b&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject" width="50%" height="50%">

(1)번식에다가 <img src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/65aa137d-ce1b-461c-a9b2-55cad5453c98/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220211%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220211T050938Z&X-Amz-Expires=86400&X-Amz-Signature=72354bacebee682f1b91dbfbec20eb1ac28a2bb09315bbd0ca9f3ac6923d5b37&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject" width="50%" height="50%">를 곱하면 (3)

(3)번식에서 <img src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/eda18094-e1b4-4f12-be2f-e2dfa2018045/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220211%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220211T051034Z&X-Amz-Expires=86400&X-Amz-Signature=9405a2468498319679173250c4c67d34f8eeb118c954128b7000e5c72c286992&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject" width="50%" height="50%">를 이용해서 (4)번 식을 만든다

<img src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/91144c07-9bf4-4967-a4d6-5b9bfae07235/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220211%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220211T051054Z&X-Amz-Expires=86400&X-Amz-Signature=e4ce0b72736b69d17dba8ed8b0e502d1f5f465eda4285b1e1ef453f206d46656&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject" width="50%" height="50%">

이제 (4) - (3)하면,

<img src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/eafb6546-d3e0-471c-ac56-b5dacbbfc9d2/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220211%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220211T051121Z&X-Amz-Expires=86400&X-Amz-Signature=df71b4c12f564b71e5e1cafb1cdfb5f7b91aad6b5586ff66672721c1a8838b27&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject" width="50%" height="50%">

이렇게 x의 계수 α의 예측값 <img src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/ab845fcc-fd2e-4795-8f9c-c330861c73b0/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220211%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220211T051158Z&X-Amz-Expires=86400&X-Amz-Signature=5150312a3ff39fc0d854792bceb20766d4d60297954a0dd976940ecd48ede91c&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject" width="50%" height="50%">은 위와 같이 구할 수 있고,

<img src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/f93c6c1d-14c6-40fd-bb0e-ad41d067b8f7/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220211%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220211T051235Z&X-Amz-Expires=86400&X-Amz-Signature=e41d7956624da77ecd06802a87add5dadd025e6ed63c7bd310f70f97dbca95c5&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject" width="50%" height="50%">는 (1)번식을 이용하여 아래와 같이 구할 수 있다. (다차원이므로, n으로 나눠주는 것..?)

<img src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/2f8cd69e-5608-4cd0-ab94-75ad66c2a88f/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220211%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220211T051303Z&X-Amz-Expires=86400&X-Amz-Signature=5916596c1298559470984490bf3f01aa50d348a2fdb44122406f2120e69be071&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject" width="50%" height="50%">

> OLS VS. MSE
> 

1️⃣ MSE (Mean Squared Error) → 모델 **성능 평가** 지표 

실제 값과 예측 값 차이를 제곱하여 평균

![https://blog.kakaocdn.net/dn/xMws5/btqZ4zBDIYe/QIZuKioJ3vhz3YtCCKkbrk/img.png](https://blog.kakaocdn.net/dn/xMws5/btqZ4zBDIYe/QIZuKioJ3vhz3YtCCKkbrk/img.png)

(생각) y_pred와 y_target의 ‘차이’를 구해서 가중치를 업데이트 하는 것이 목표 

2️⃣ OLS (ordinary least squares) → 선형 회귀 **모델을 만들기 위한** 선형 최소 제곱법
 
<img src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/c3b849cc-3c88-4a82-97b8-d2d58fd72414/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220211%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220211T051341Z&X-Amz-Expires=86400&X-Amz-Signature=a981c00d2ec2eb435ada385ef1ebd22b5385e9f87cc99223303a04cdfcaab426&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject" width="50%" height="50%">

(생각) β와 α를 직접 구해서 ‘식’을 완성하는 것이 목표 

### 참고

- [선형회귀분석 Linear Regression , SSE, OLS (tistory.com)](https://xiang32.tistory.com/11)
- [https://throwexception.tistory.com/943](https://throwexception.tistory.com/943)
- [데이터과학을 위한 통계 리뷰 - 13일차 (회귀와 예측,적합값과 잔차,최소제곱,다중회귀분석,OLS,RMSE,MSE,MAE,RMSLE) (tistory.com)](https://datacook.tistory.com/45)
- [데이터과학 유망주의 매일 글쓰기 — 쉬어가는 한 주 — 4. OLS(Ordinary Least Squared) 에러 | by 배우는 자(Learner Of Life) | Medium](https://conanmoon.medium.com/%EB%8D%B0%EC%9D%B4%ED%84%B0%EA%B3%BC%ED%95%99-%EC%9C%A0%EB%A7%9D%EC%A3%BC%EC%9D%98-%EB%A7%A4%EC%9D%BC-%EA%B8%80%EC%93%B0%EA%B8%B0-%EC%89%AC%EC%96%B4%EA%B0%80%EB%8A%94-%ED%95%9C-%EC%A3%BC-4-28f5d18266d7)

