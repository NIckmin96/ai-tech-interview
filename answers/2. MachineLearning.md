<div align='center'>
  <h1>🤖 Machine Learning 🤖</h1>
</div>


## Questions ❓

- [알고 있는 metric에 대해 설명해주세요. (ex. RMSE, MAE, recall, precision ...)](#no1)
- [정규화를 왜 해야할까요? 정규화의 방법은 무엇이 있나요?](#no2)
- [Local Minima와 Global Minima에 대해 설명해주세요.](#no3)

---

### No.1

**알고 있는 metric에 대해 설명해주세요. (ex. RMSE, MAE, recall, precision ...)**

1. RMSE-like metrics
   * [MAE](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/MeanAbsoluteError): Mean Absolute Error, 오차 평균; 오차의 단위가 실제 타겟값의 단위와 똑같다는 특징이 있으며 이상치에 덜 민감하다.
   * [RMSE](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/RootMeanSquaredError): Root Mean Squared Error, 오차 제곱 평균의 제곱근; MAE와 마찬가지로 오차의 단위가 실제 타겟값의 단위와 똑같아서 직관적이다. MAE와는 달리 큰 오차값이 더 반영되어 이상치에 더 민감하다는 특징을 갖고 있다.
   * [MSE](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/MeanSquaredError): Mean Squared Error, 오차 제곱 평균; RMSE와 같이 큰 오차값을 더 반영하는 평가지표지만, 실제 타겟값과 단위가 달라서 직관적이지는 않다. MAE, RMSE와 같이 회귀 문제에서 자주 사용되는 평가지표다.
   * [MAPE](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/MeanAbsolutePercentageError): Mean Absolute Percentage Error, 오차 평균 백분율; 오차를 실제값 y로 나누어 MAE를 백분율 단위로 변경한 것으로, MAE와 많은 공통점을 지니지만 y가 0일 때 사용할 수 없다는 단점이 추가로 존재한다. 백분율 단위의 직관성이 장점이지만, 예측값과 실제값의 대소관계가 지표의 크기에 반영이 되는 특징이 있어 주의가 필요하다. (예/ n=1일 때, 예측값:10/실제값:20 → MAPE = 50% ; 예측값:20/실제값:10 → MAPE = 100%)
2. confusion matrix related metrics
   * [Precision](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Precision)(정밀도): True Positives / Predicted Positives = True Positives / (True Positives + False Positives): 1종 오류와 관련이 있는 분류 평가 지표. (예/ 스팸 방지 - 스팸메일이 받은메일함으로 분류되는 것보다 정상 메일이 스팸메일함으로 분류되는 것을 더 지양)
   * [Recall](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Recall) = Sensitivity(민감도): True Positives / Real Positives = True Positives / (True Positives + False Negatives); 2종 오류와 관련이 있는 분류 평가 지표. (예/ 의료 데이터 분석 - 양성으로 잘못 분류하는 것보다 음성으로 잘못 분류하여 환자를 놓치는 경우를 더 지양)
   * Specificity(특이도): True Negatives / Real Negatives = True Negatives / (True Negatives + False Positives); False Alarm(False Positive)를 방지하고자 할때 사용. (예/ 마약복용자를 구속하지 않는 것보다 일반인을 잘못 구속하는 경우를 더 지양)
   * [Precision at Recall](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/PrecisionAtRecall) / [Recall at Precision](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/RecallAtPrecision) : 특정 Recall 값에서의 Precision 측정 또는 특정 Precision 값에서의 Recall 측정
3. [AUC](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/AUC)
   * ROC-AUC: ROC(Receiver Operating Characteristic) 곡선 아래의 면적(0~1); True Positive Rate(=Recall=TP/(TP+FN))과 False Positive Rate(=FP/(FP+TN))의 tradeoff 관계를 시각화하는 지표; 랜덤한 이진 분류의 경우 ROC-AUC 값은 0.5.
   * PR-AUC: Precision-Recall 곡선 아래의 면적(0~1); 음악 장르와 같이 대부분이 0으로 이루어진 (imbalanced 한) 레이블 벡터 y를 타겟으로 할 때는 PR-AUC가 ROC-AUC보다 더 정확한 직관을 주는 것으로 알려져 있음. (True Negative의 영향 때문)
4. crossentropy
   * [binary crossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/BinaryCrossentropy): 이진분류 문제에 사용할 수 있는 crossentropy 기반 분류 지표.
   * [categorical crossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/CategoricalCrossentropy): multi-label분류 문제에 사용할 수 있는 crossentropy 기반 분류 지표.

참고문헌
- [TensorFlow tf.keras.metrics API docs](https://www.tensorflow.org/api_docs/python/tf/keras/metrics)
- [Regression Metrics for Machine Learning](https://machinelearningmastery.com/regression-metrics-for-machine-learning/)
- [Tutorial: Understanding Regression Error Metrics in Python](https://www.dataquest.io/blog/understanding-regression-error-metrics/)
- [Accuracy, Recall, Precision, F-Score & Specificity, which to optimize on?](https://towardsdatascience.com/accuracy-recall-precision-f-score-specificity-which-to-optimize-on-867d3f11124)
- [F1 Score vs ROC AUC vs Accuracy vs PR AUC: Which Evaluation Metric Should You Choose?](https://neptune.ai/blog/f1-score-accuracy-roc-auc-pr-auc)
- [이진 분류기 성능 평가방법 AUC(area under the ROC curve)의 이해.txt](https://bskyvision.com/1165)
- [Cross-entropy for classification](https://towardsdatascience.com/cross-entropy-for-classification-d98e7f974451)

---
### No.2
**정규화를 왜 해야할까요? 정규화의 방법은 무엇이 있나요?**

다양한 정규화 방법들을 통해서 기계학습 알고리즘의 성능을 증가시킬 수 있으며, 알고리즘들마다 정규화의 효과가 다를 수 있어 실험을 해보는 것이 좋다. 거리기반의 SVM, KNN 알고리즘과 MLP 알고리즘은 특히 정규화의 효능이 좋은 편이다.

1. Normalization (min-max normalization): 값들을 0에서 1사이 범위로 rescaling하는 것을 뜻한다.
2. Standardization (Z-score standardization): 평균 0 표준편차 1의 분포를 띄도록 rescaling하는 것을 뜻한다.

특히 딥러닝에서 정규화는 오랜 기간동안 연구 대상으로 주목 받고 있었으며, 정규화를 수행하는 방향 또한 중요하다고 알려져 있다.

![normalization](https://miro.medium.com/max/1400/1*r0HM4TvZvvceXcJIpDJmDQ.png)

1. Batch Normalization: mini-batch 내 같은 feature들끼리 정규화를 수행하는 방법이다. 보통 CNN 모델에서 많이 사용된다. batch 사이자가 너무 작을 때는 오히려 악역향을 끼칠 수 있다고도 한다.
2. Layer Normalization: 각 데이터 포인트 전체에 대하여 정규화를 수행하는 방법이다. 보통 RNN 또는 Transformer 모델에서 많이 사용된다.

  참고문헌
  - [Normalization vs Standardization — Quantitative analysis](https://towardsdatascience.com/normalization-vs-standardization-quantitative-analysis-a91e8a79cebf)
  - [Normalization Techniques in Deep Neural Networks](https://medium.com/techspace-usict/normalization-techniques-in-deep-neural-networks-9121bf100d8)

---

### No.3
**Local Minima와 Global Minima에 대해 설명해주세요.**

(손실) 함수 전체의 가장 최소값이 global minima이며, gradient decent 등의 최적화 알고리즘으로 찾을 수 있는 global minima 외 최소값들을 local minima라고 한다. 기계학습 최적화 알고리즘들은 local minima에 빠져서 global minima를 찾지 못할 가능성이 항상 존재한다.

![animation](https://vitalflux.com/wp-content/uploads/2020/10/local_minima_vs_global_minima.gif)

global minima를 올바르게 찾기 위해서는 feature engineering을 조심히 히야하며, 다양한 learning rate schedule과 여러 step수를 실험해볼 필요가 있다.

참고문헌

- [Local & Global Minima Explained with Examples](https://vitalflux.com/local-global-maxima-minima-explained-examples/)
---

